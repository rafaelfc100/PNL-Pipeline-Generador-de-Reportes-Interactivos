# PNL-Pipeline-Generador-de-Reportes-Interactivos
Pipeline de AnÃ¡lisis de Texto en Python que automatiza el flujo de trabajo completo: desde el preprocesamiento, pasando por anÃ¡lisis descriptivo (Nubes de Palabras, N-gramas) y Modelado de TÃ³picos (BERTopic) . El proceso incluye reducciÃ³n de dimensionalidad UMAP , detecciÃ³n de outliers  y finaliza con un informe HTML interactivo.
Este proyecto implementa un pipeline completo de anÃ¡lisis de texto, dividido en bloques independientes que trabajan de forma secuencial:

lectura de datos,

preprocesamiento,

vectorizaciÃ³n,

entrenamiento de modelos clÃ¡sicos,

evaluaciÃ³n y mÃ©tricas.

Todo el sistema fue diseÃ±ado para ser fÃ¡cil de ejecutar desde la terminal, usando argumentos y archivos de prueba incluidos en el repositorio.

El objetivo principal es contar con un flujo reproducible, modular y entendible que permita analizar datos textuales desde cero.

ğŸš€ Funcionalidades principales
ğŸ“¥ Entrada del sistema

El programa toma como entrada un archivo .csv y una columna que contiene los textos.
Los parÃ¡metros se manejan desde la terminal mediante argparse.

Ejemplo general (incluido en commands.txt):

python main.py --input "data/ejemplo.csv" --columna "texto"

ğŸ”§ Bloque 1 â€“ Manejo de argumentos

Este mÃ³dulo define todos los parÃ¡metros que el usuario puede activar:

ruta del CSV

nombre de la columna de texto

opciÃ³n para activar el preprocesamiento

tipo de vectorizaciÃ³n

modelo de clasificaciÃ³n

modo verboso

Los argumentos permiten combinar distintos flujos sin modificar el cÃ³digo.

ğŸ§¹ Bloque 2 â€“ Carga de archivos

Incluye funciones para:

leer CSV con codificaciones variadas

validaciÃ³n de columnas

limpieza bÃ¡sica del dataset (NaN, espacios, textos vacÃ­os)

El bloque siempre regresa un DataFrame limpio y listo para procesar.

âœï¸ Bloque 3 â€“ Preprocesamiento de texto

AquÃ­ se realiza el tratamiento del texto antes de vectorizarlo.
Tu implementaciÃ³n incluye:

âœ”ï¸ ConversiÃ³n a minÃºsculas
âœ”ï¸ EliminaciÃ³n de signos, nÃºmeros y URLs
âœ”ï¸ NormalizaciÃ³n de espacios
âœ”ï¸ TokenizaciÃ³n por expresiones regulares
âœ”ï¸ Stopwords personalizadas
âœ”ï¸ LematizaciÃ³n sencilla opcional

El resultado final queda en una columna llamada:

texto_procesado

ğŸ”¢ Bloque 4 â€“ VectorizaciÃ³n

Se implementaron tres mÃ©todos clÃ¡sicos:

Bag of Words

TFâ€“IDF

CountVectorizer

Cada uno puede activarse desde la lÃ­nea de comandos.

El vector resultante se usa directamente por los clasificadores.

ğŸ¤– Bloque 5 â€“ Clasificadores

Incluyes el entrenamiento de varios modelos clÃ¡sicos:

RegresiÃ³n logÃ­stica

Naive Bayes

SVM lineal

Ãrbol de decisiÃ³n

KNN

Cada modelo genera:

matriz de confusiÃ³n

accuracy

reporte de clasificaciÃ³n

Los resultados se imprimen en consola.

ğŸ“„ Bloque 6 â€“ EjecuciÃ³n orquestada (main.py)

Este archivo une todos los bloques y ejecuta el pipeline completo:

Leer argumentos

Cargar CSV

Preprocesar texto

Vectorizar

Entrenar modelo

Mostrar mÃ©tricas

El flujo es completamente automÃ¡tico.

ğŸ“ Estructura del proyecto
data/
    ejemplo.csv
    comandos_de_prueba.txt   # ejecutables que usa el proyecto
modulos/
    bloque1_args.py
    bloque2_carga.py
    bloque3_preproc.py
    bloque4_vectorizacion.py
    bloque5_modelos.py
main.py
README.md

ğŸ“¦ Requisitos y versiones usadas

Estas son las versiones reales que anotaste en tu archivo commands.txt:

Python 3.13
numpy 2.1.1
pandas 2.2.2
scikit-learn 1.5.0
nltk 3.9


(Si deseas agrego mÃ¡s versiones o verifico las que tienes instaladas.)

ğŸ“‚ Archivo ejecutable: commands_example.txt

Incluye ejemplos listos para correr:

python main.py --input "data/ejemplo.csv" --columna "texto" --modelo "svm"
python main.py --input "data/ejemplo.csv" --columna "comentario" --preprocesar 1 --vector "tfidf"
python main.py --input "data/otra.csv" --columna "review" --modelo "logreg"

ğŸ‘¨â€ğŸ’» Autor

Alejandro FrÃ­as CortÃ©z â€” Proyecto acadÃ©mico de procesamiento de lenguaje natural en Python.
